random.color=FALSE,
colors=brewer.pal(9,"Reds"))
})
},
options = list(height = 600)
)
#setwd("C:/Users/samsung/ADS/Spr2017-Proj1-kenkcchew/doc")
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels",
"wordcloud", "tidytext", "shiny",
"reshape2", "pracma", "knitr", "formattable",
"httpuv", "caTools")
# check packages that need to be installed
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE, repos = "http://cran.us.r-project.org")
}
# load packages
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("topicmodels")
library("wordcloud")
library("tidytext")
library("shiny")
library("reshape2")
library("pracma")
library("knitr")
library("formattable")
library("httpuv")
library("caTools")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
# download and process speeches info's txt file
# Building FullName with format FirstMLast for details on inauguration speeches
speeches_date <- read.table(file = "../data/InauguationDates.txt", sep = "\t", header = T)
colnames(speeches_date)[2:5] <- c(1:4)
speeches_date<- melt(speeches_date, id.vars = "PRESIDENT", value.name = "Date", variable.name = "Term")
speeches_date <- speeches_date[which(speeches_date$Date != ""), ]
# convert dates to Date format
speech_dates_vec <- t(sapply(strsplit(as.character(speeches_date$Date), "/", fixed = T), '['))
speeches_date$Date <- as.Date( paste(speech_dates_vec[, 3], speech_dates_vec[, 1], speech_dates_vec[, 2], sep = "." )  , format = "%Y.%m.%d" )
speeches_date <- speeches_date[order(speeches_date$Date),]
FirstName <- sapply(strsplit(as.character(speeches_date$PRESIDENT), " ", fixed = T), '[', 1)
MiddleLastName <- sapply(strsplit(as.character(speeches_date$PRESIDENT), " ", fixed = T), '[', -1)
LastName <- list()
M <- list()
for (i in 1:length(MiddleLastName)) {
if (length(MiddleLastName[i][[1]]) == 1) {
LastName[i] <- MiddleLastName[i][[1]]
M[i] <- ""
} else{
LastName[i] <- MiddleLastName[i][[1]][2]
M[i] <- substring(MiddleLastName[i][[1]][1], 1, 1)
}
}
speeches_date$NameTerm <- paste0(FirstName, M, LastName, "-", speeches_date$Term)
speeches_date$FileName <- paste0("inaug", FirstName, M, LastName, "-", speeches_date$Term, ".txt")
# Creating date min/max ranges for analysis later
speeches_date$DateMinus7 <- speeches_date$Date - 7
speeches_date$DateMinus15 <- speeches_date$Date - 15
#speeches_date$DateMinus30 <- speeches_date$Date - 30
speeches_date$DatePlus7 <- speeches_date$Date + 7
speeches_date$DatePlus15 <- speeches_date$Date + 15
#speeches_date$DatePlus30 <- speeches_date$Date + 30
# Step 1b: Download and process speeches
#
# For the speeches, we remove extra white space, convert all letters to the lower case, remove stop wrods, removed empty words due to formatting errors, and remove punctuation. Then we compute the [Document-Term Matrix (DTM)](https://en.wikipedia.org/wiki/Document-term_matrix).
# download speeches text
folder.path="../data/InauguralSpeeches/Subset"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
SpeechCorpus <-Corpus(DirSource(folder.path))
speeches_shortened <- sub("inaug", "", speeches)
speeches_shortened <- sub(".txt", "", speeches_shortened)
SpeechCorpus<-tm_map(SpeechCorpus, stripWhitespace)
SpeechCorpus<-tm_map(SpeechCorpus, content_transformer(tolower))
SpeechCorpus<-tm_map(SpeechCorpus, removeWords, stopwords("english"))
SpeechCorpus<-tm_map(SpeechCorpus, removeNumbers)
SpeechCorpus<-tm_map(SpeechCorpus, removePunctuation)
SpeechCorpus.up <- SpeechCorpus[c(1, 3, 4, 5, 8)]
SpeechCorpus.down <- SpeechCorpus[-c(1, 3, 4, 5, 8)]
# Compute term-document matrix by count of words
tdm.up <- TermDocumentMatrix(SpeechCorpus.up)
tdm.down <- TermDocumentMatrix(SpeechCorpus.down)
# this has speeches by inauguration
tdm.tidy.up <- tidy(tdm.up)
tdm.tidy.down <- tidy(tdm.down)
# remove .txt and inaug from speeches name
docNames <- tdm.tidy.up$document
docNames <- sub("inaug", "", docNames)
docNames <- sub(".txt", "", docNames)
tdm.tidy.up$document <- docNames
docNames <- tdm.tidy.down$document
docNames <- sub("inaug", "", docNames)
docNames <- sub(".txt", "", docNames)
tdm.tidy.down$document <- docNames
tdm.overall.up <- summarise(group_by(tdm.tidy.up, term), sum(count))
tdm.overall.down <- summarise(group_by(tdm.tidy.down, term), sum(count))
# #Step 4 - compute TF-IDF weighted document-term matrices for individual speeches.
# As we would like to identify interesting words for each inaugural speech, we use [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to weigh each term within each speech. It highlights terms that are more specific for a particular speech.
# Compute TF-IDF weighted document-term matrices for individual speeches
dtm.up <- DocumentTermMatrix(SpeechCorpus.up,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
dtm.down <- DocumentTermMatrix(SpeechCorpus.down,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
SpeechCorpus.dtm.up <- tidy(dtm.up)
SpeechCorpus.dtm.down <- tidy(dtm.down)
# remove .txt and inaug from speeches name
docNames <- SpeechCorpus.dtm.up$document
docNames <- sub("inaug", "", docNames)
docNames <- sub(".txt", "", docNames)
SpeechCorpus.dtm.up$document <- docNames
docNames <- SpeechCorpus.dtm.down$document
docNames <- sub("inaug", "", docNames)
docNames <- sub(".txt", "", docNames)
SpeechCorpus.dtm.down$document <- docNames
speeches_up <- speeches_shortened[c(1, 3, 4, 5, 8)]
speeches_down <- speeches_shortened[-c(1, 3, 4, 5, 8)]
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Speeches (Mkts Up)',
"Combined Speeches (Up)",
selected=speeches_shortened[1])),
column(4, selectInput('speech1', 'Speeches (Mkts Down)',
"Combined Speeches (Down)",
selected=speeches_shortened[1])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(tdm.overall.up$term,
tdm.overall.up$`sum(count)`,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Greens"))
wordcloud(tdm.overall.down$term,
tdm.overall.down$`sum(count)`,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Reds"))
})
},
options = list(height = 600)
)
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Speeches (Mkts Up)',
"Combined Speeches (Up)",
selected=speeches_shortened[1])),
column(4, selectInput('speech1', 'Speeches (Mkts Down)',
"Combined Speeches (Down)",
selected=speeches_shortened[1])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(SpeechCorpus.dtm.up$term,
SpeechCorpus.dtm.up$count,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Greens"))
wordcloud(SpeechCorpus.dtm.down$term,
SpeechCorpus.dtm.down$count,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Reds"))
})
},
options = list(height = 600)
)
#setwd("C:/Users/samsung/ADS/Spr2017-Proj1-kenkcchew/doc")
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels",
"wordcloud", "tidytext", "shiny",
"reshape2", "pracma", "knitr", "formattable",
"httpuv", "caTools")
# check packages that need to be installed
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE, repos = "http://cran.us.r-project.org")
}
# load packages
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("topicmodels")
library("wordcloud")
library("tidytext")
library("shiny")
library("reshape2")
library("pracma")
library("knitr")
library("formattable")
library("httpuv")
library("caTools")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
# download and process speeches info's txt file
# Building FullName with format FirstMLast for details on inauguration speeches
speeches_date <- read.table(file = "../data/InauguationDates.txt", sep = "\t", header = T)
colnames(speeches_date)[2:5] <- c(1:4)
speeches_date<- melt(speeches_date, id.vars = "PRESIDENT", value.name = "Date", variable.name = "Term")
speeches_date <- speeches_date[which(speeches_date$Date != ""), ]
# convert dates to Date format
speech_dates_vec <- t(sapply(strsplit(as.character(speeches_date$Date), "/", fixed = T), '['))
speeches_date$Date <- as.Date( paste(speech_dates_vec[, 3], speech_dates_vec[, 1], speech_dates_vec[, 2], sep = "." )  , format = "%Y.%m.%d" )
speeches_date <- speeches_date[order(speeches_date$Date),]
FirstName <- sapply(strsplit(as.character(speeches_date$PRESIDENT), " ", fixed = T), '[', 1)
MiddleLastName <- sapply(strsplit(as.character(speeches_date$PRESIDENT), " ", fixed = T), '[', -1)
LastName <- list()
M <- list()
for (i in 1:length(MiddleLastName)) {
if (length(MiddleLastName[i][[1]]) == 1) {
LastName[i] <- MiddleLastName[i][[1]]
M[i] <- ""
} else{
LastName[i] <- MiddleLastName[i][[1]][2]
M[i] <- substring(MiddleLastName[i][[1]][1], 1, 1)
}
}
speeches_date$NameTerm <- paste0(FirstName, M, LastName, "-", speeches_date$Term)
speeches_date$FileName <- paste0("inaug", FirstName, M, LastName, "-", speeches_date$Term, ".txt")
# Creating date min/max ranges for analysis later
speeches_date$DateMinus7 <- speeches_date$Date - 7
speeches_date$DateMinus15 <- speeches_date$Date - 15
#speeches_date$DateMinus30 <- speeches_date$Date - 30
speeches_date$DatePlus7 <- speeches_date$Date + 7
speeches_date$DatePlus15 <- speeches_date$Date + 15
#speeches_date$DatePlus30 <- speeches_date$Date + 30
# Step 1b: Download and process speeches
#
# For the speeches, we remove extra white space, convert all letters to the lower case, remove stop wrods, removed empty words due to formatting errors, and remove punctuation. Then we compute the [Document-Term Matrix (DTM)](https://en.wikipedia.org/wiki/Document-term_matrix).
# download speeches text
folder.path="../data/InauguralSpeeches/Subset"
speeches=list.files(path = folder.path, pattern = "*.txt")
prex.out=substr(speeches, 6, nchar(speeches)-4)
SpeechCorpus <-Corpus(DirSource(folder.path))
speeches_shortened <- sub("inaug", "", speeches)
speeches_shortened <- sub(".txt", "", speeches_shortened)
SpeechCorpus<-tm_map(SpeechCorpus, stripWhitespace)
SpeechCorpus<-tm_map(SpeechCorpus, content_transformer(tolower))
SpeechCorpus<-tm_map(SpeechCorpus, removeWords, stopwords("english"))
SpeechCorpus<-tm_map(SpeechCorpus, removeNumbers)
SpeechCorpus<-tm_map(SpeechCorpus, removePunctuation)
SpeechCorpus.up <- SpeechCorpus[c(1, 3, 4, 5, 8)]
SpeechCorpus.down <- SpeechCorpus[-c(1, 3, 4, 5, 8)]
# Compute term-document matrix by count of words
tdm.up <- TermDocumentMatrix(SpeechCorpus.up)
tdm.down <- TermDocumentMatrix(SpeechCorpus.down)
# this has speeches by inauguration
tdm.tidy.up <- tidy(tdm.up)
tdm.tidy.down <- tidy(tdm.down)
# remove .txt and inaug from speeches name
docNames <- tdm.tidy.up$document
docNames <- sub("inaug", "", docNames)
docNames <- sub(".txt", "", docNames)
tdm.tidy.up$document <- docNames
docNames <- tdm.tidy.down$document
docNames <- sub("inaug", "", docNames)
docNames <- sub(".txt", "", docNames)
tdm.tidy.down$document <- docNames
tdm.overall.up <- summarise(group_by(tdm.tidy.up, term), sum(count))
tdm.overall.down <- summarise(group_by(tdm.tidy.down, term), sum(count))
# #Step 4 - compute TF-IDF weighted document-term matrices for individual speeches.
# As we would like to identify interesting words for each inaugural speech, we use [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to weigh each term within each speech. It highlights terms that are more specific for a particular speech.
# Compute TF-IDF weighted document-term matrices for individual speeches
dtm.up <- DocumentTermMatrix(SpeechCorpus.up,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
dtm.down <- DocumentTermMatrix(SpeechCorpus.down,
control = list(weighting = function(x)
weightTfIdf(x,
normalize =FALSE),
stopwords = TRUE))
SpeechCorpus.dtm.up <- tidy(dtm.up)
SpeechCorpus.dtm.down <- tidy(dtm.down)
# remove .txt and inaug from speeches name
docNames <- SpeechCorpus.dtm.up$document
docNames <- sub("inaug", "", docNames)
docNames <- sub(".txt", "", docNames)
SpeechCorpus.dtm.up$document <- docNames
docNames <- SpeechCorpus.dtm.down$document
docNames <- sub("inaug", "", docNames)
docNames <- sub(".txt", "", docNames)
SpeechCorpus.dtm.down$document <- docNames
speeches_up <- speeches_shortened[c(1, 3, 4, 5, 8)]
speeches_down <- speeches_shortened[-c(1, 3, 4, 5, 8)]
# Read speeches into speech_list for sentiment analysis
speech1=paste(readLines("../data/InauguralSpeeches/Subset/inaugBarackObama-1.txt",
n=-1, skipNul=TRUE), collapse=" ")
speech2=paste(readLines("../data/InauguralSpeeches/Subset/inaugBarackObama-2.txt",
n=-1, skipNul=TRUE), collapse=" ")
speech3=paste(readLines("../data/InauguralSpeeches/Subset/inaugDonaldJTrump-1.txt",
n=-1, skipNul=TRUE), collapse=" ")
speech4=paste(readLines("../data/InauguralSpeeches/Subset/inaugGeorgeBush-1.txt",
n=-1, skipNul=TRUE), collapse=" ")
speech5=paste(readLines("../data/InauguralSpeeches/Subset/inaugGeorgeWBush-1.txt",
n=-1, skipNul=TRUE), collapse=" ")
speech6=paste(readLines("../data/InauguralSpeeches/Subset/inaugGeorgeWBush-2.txt",
n=-1, skipNul=TRUE), collapse=" ")
speech7=paste(readLines("../data/InauguralSpeeches/Subset/inaugRonaldReagan-2.txt",
n=-1, skipNul=TRUE), collapse=" ")
speech8=paste(readLines("../data/InauguralSpeeches/Subset/inaugWilliamJClinton-1.txt",
n=-1, skipNul=TRUE), collapse=" ")
speech9=paste(readLines("../data/InauguralSpeeches/Subset/inaugWilliamJClinton-2.txt",
n=-1, skipNul=TRUE), collapse=" ")
speech_up = data.frame(NameTerm = speeches_up,
fulltext = c(speech1, speech3, speech4, speech5, speech8))
speech_down = data.frame(NameTerm = speeches_down,
fulltext = c(speech2, speech6, speech7, speech9))
shinyApp(
ui = fluidPage(
fluidRow(style = "padding-bottom: 20px;",
column(4, selectInput('speech1', 'Speeches (Mkts Up)',
"Combined Speeches (Up)",
selected=speeches_shortened[1])),
column(4, selectInput('speech1', 'Speeches (Mkts Down)',
"Combined Speeches (Down)",
selected=speeches_shortened[1])),
column(4, sliderInput('nwords', 'Number of words', 3,
min = 20, max = 200, value=100, step = 20))
),
fluidRow(
plotOutput('wordclouds', height = "400px")
)
),
server = function(input, output, session) {
output$wordclouds <- renderPlot(height = 400, {
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(SpeechCorpus.dtm.up$term,
SpeechCorpus.dtm.up$count,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Greens"))
wordcloud(SpeechCorpus.dtm.down$term,
SpeechCorpus.dtm.down$count,
scale=c(4,0.5),
max.words=input$nwords,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Reds"))
})
},
options = list(height = 600)
)
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(tdm.overall.up$term,
tdm.overall.up$`sum(count)`,
scale=c(4,0.5),
max.words=120,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
wordcloud(tdm.overall.down$term,
tdm.overall.down$`sum(count)`,
scale=c(4,0.5),
max.words=120,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Reds"))
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(SpeechCorpus.dtm.up$term,
SpeechCorpus.dtm.up$count,
scale=c(4,0.5),
max.words=120,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Greens"))
wordcloud(SpeechCorpus.dtm.down$term,
SpeechCorpus.dtm.down$count,
scale=c(4,0.5),
max.words=120,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Reds"))
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(SpeechCorpus.dtm.up$term,
SpeechCorpus.dtm.up$count,
scale=c(4,0.5),
max.words=100,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Greens"))
wordcloud(SpeechCorpus.dtm.down$term,
SpeechCorpus.dtm.down$count,
scale=c(4,0.5),
max.words=120,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Reds"))
par(mfrow=c(1,2), mar = c(0, 0, 3, 0))
wordcloud(SpeechCorpus.dtm.up$term,
SpeechCorpus.dtm.up$count,
scale=c(4,0.5),
max.words=150,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Greens"))
wordcloud(SpeechCorpus.dtm.down$term,
SpeechCorpus.dtm.down$count,
scale=c(4,0.5),
max.words=120,
min.freq=1,
random.order=FALSE,
rot.per=0,
use.r.layout=FALSE,
random.color=FALSE,
colors=brewer.pal(9,"Reds"))
